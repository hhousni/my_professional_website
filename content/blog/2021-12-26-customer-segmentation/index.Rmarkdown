---
title: Customer Segmentation
layout: single-sidebar
date: '2021-12-26'
categories:
  - Machine Learning
  - Marketing
tags:
  - R
  - Marketing
slug: rstudio-instructor-certification-tidyverse
subtitle: Using K-mean algorithm
summary: This paper aimed to perform a customer segmentation in R programming. We used a Shopping mall customers dataset to implement it.
lastmod: 2021-03-31
featured: yes
draft: no
image:
  placement: 1
  caption: '[Illustration from starline on Freepik](https://www.freepik.com/free-vector/segmentation-illustration-concept_6202467.htm#query=segmentation&position=6&from_view=search)'
  focal_point: Center
  preview_only: no
output:
  blogdown::html_page:
    toc: yes
    number_sections: no
    toc_depth: 1
links:
  - icon: github
    icon_pack: fab
    name: post materials
    url: https://github.com/hhousni/Customer_segmentation
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

My life is composed by different groups, my family, my friends, my co-workers, my clients etc. Each group has his needs and his expectations. In order to Satisfy them, I set up different forms of communication and interaction.
Companies face the same challenges as we do in our daily lives.They communicate and interact with different customers. To succeed, they have to be able to identify groups of people that have similar characteristics among their customers, in order to: 

- Better understand and target their customers
- Gain competitive advantage against competitors
- Determine new market opportunities 
- Focus on the most profitable customers
- Upsell and cross-sell other products and services. 

**Customer segmentation** is the practice of dividing customer into groups based on similar characteristics. 
This paper aims to perform a **Customers segmentation** using k-means algorithm in R programming. 

# Data Loading and exploratory Analysis 

In general, to perform a cluster analysis, the dataset should be prepared as follows: 

- Columns should be the variables and Row the observations 
- The dataset should not contain any missing values or blank. Any missing values should be removed or estimated 
- The data should be standardized in order to make the variables comparable. 

## Data Loading and prepration 

```{r}
#The Pacman package is going to be used as package manager
if(!require("pacman")) install.packages("pacman")
data <- read.csv("https://raw.githubusercontent.com/hhousni/Customer_segmentation/main/Mall_Customers.csv")
```

**Data overview**

```{r}
str(data)
```

The dataset is composed by 200 observations and 5 variables:

- CustomerID: The unique customer's ID
- Gender: customer's gender 
- Age: customer's age  
- Annual Income (k$): Customer's annual income 
- Spending Score: Score given to the customer based on the money spent and the customer's behavior.  


Checking, if there are missing values in the dataset. 
```{r}
#Find the number of NAs in each variable 
lapply(data,function(x) {length(which(is.na(x)))})
#Find the number of blank in each variable
lapply(data, function(x) {length(which((x=="")))})
```

The dataset does not contain missing values as both NAs and blank spaces.  

## Exploratory Analysis 

```{r}
head(data)
```

**Gender Visualization** 

```{r}
p_load(ggplot2)

ggplot(data, aes(Gender, fill=Gender)) +
  geom_bar(alpha=.4, col='black') + 
  ggtitle("Gender Comparision") + 
  xlab("Gender") + 
  ylab("Number of Customer")
```


Woman represent the majority of the Shopping mall customers. 

**Age distribution** 


```{r}
summary(data$Age)

ggplot(data, aes(Age)) + geom_histogram(binwidth = 5, breaks=seq(15,70, by=5),
                                        col="black",
                                        fill=I('blue'),
                                        alpha=.2)  + 
  labs(title = "Histogram for Age", x="Age",y="Count")

```

Customers age is between 18 to 70 years old. The average customer is 38.85 years old and the median is 36 years old. The majority of customer are between 20 to 50 years old. 


**Annual Income Distribution** 

```{r}

summary(data$Annual.Income..k..)

ggplot(data, aes(Annual.Income..k..)) + geom_histogram(binwidth = 5, breaks=seq(10,140, by=10),
                                        col="black",
                                        fill=I('blue'),
                                        alpha=.2) +
  labs(title = "Histogram for Annual Income", x="Annual Income Class",y="Frequency")
```

In average, the customers earn 60.56 k(\$) per year, the minimum income is 15k(\$) per year and the maximum is 137 k(\$) per year. The major part of customers earn less than 90 k(\$) per year.  

**Spending Score distribution** 


```{r}

summary(data$Spending.Score..1.100.)

ggplot(data, aes(Spending.Score..1.100.)) + geom_histogram(binwidth = 5, breaks=seq(0,100, by=10),
                                        col="black",
                                        fill=I('blue'),
                                        alpha=.2) +
  labs(title = "Histogram for Spending Score", x="Spending Score Class",y="Frequency")

```


# Implementation of k-means


##Algorithme description 


**K-means clustering** is an unsupervised machine learning algorithm that splits unlabeled dataset into a number of pre-defined clusters (k) according to their properties. The goal of the k-means algorithm is to minimize the sum of distance between the data point and their corresponding cluster. 

k-means algorithm works as follow:

1. Decide the number of cluster (k)
2. Select a number of K centroids
3. Assign for each data point to their closer centroid by using distance measurement such as Euclidean or Manhattan distance.\
4. For Every centroid, move the centroid to the average of the point assigned to that centroid.
5. Repeat step 3 and 4 until the centroids assignment no longer changes.

**To perform the k-means algorithm, the number of cluster has to be specified in advance. Different methods can be used to select the optimal cluster number**. 

**Elbow method** 

- This method runs k-means clustering for a range of values  (for instance, by varying k from 1 to 10 ) 
- For each value of K calculate the total within-cluster sum of square
- Plot the curve of total within-cluster sum of square 
- The location of a bend in the plot (knee) is an indicator of the number of clusters
    
**Silhouette method**

- The average silhouette method calculates the mean of silhouette observations for different k values. With the optimal number of k clusters, one can maximize the average silhouette over significant values for k clusters.
    
**Gap statistic**

- The gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic. 

### 2.2 Slecting the Optimum Number of clusters 

**Elbow method** 

```{r}
p_load(purrr)
# function to calculate total intra-cluster sum of square
set.seed(123)
p_load(cluster,gridExtra,grid, factoextra)
fviz_nbclust(data[,3:5], kmeans, method = "wss") + geom_vline(xintercept = 4, linetype=2) + labs(subtitle = "Elbow method")
```

The above graph seems to show a bend on the cluster number 4. We can conclude that 4 is the appropriate numbers of clusters. 

**Silhouette method**

```{r}
set.seed(123)
fviz_nbclust(data[,3:5], kmeans, method = "silhouette") + labs(subtitle = "Silhouette method")
```

According to the silhouette method, 6 is the optimal number of cluster.  

**Gap statistic method**

```{r}
set.seed(123)
fviz_nbclust(data[,3:5], kmeans, nstart=25, method = "gap_stat", nboot = 50) + labs(subtitle = "Gap statistic method")
```

According to the Gap statistic method, 6 is the optimal number of cluster. 

**Two among the three different methods of selecting the optimal number of cluster concluded that 6 is the optimal number of cluster. To implement the K-mean algorithm we are going to use 6 clusters.**

### 2.3 Results 

```{r}
set.seed(123)
result <- kmeans(data[,3:5],6,iter.max = 100, nstart = 50, algorithm="Lloyd")
result
```

**Visualizing the clustering Results using Principle components analysis**

```{r}
pcclust <- prcomp(data[,3:5], scale=FALSE) 
summary(pcclust)
```

```{r}
pcclust$rotation[,1:2]
```
```{r}
set.seed(1)
ggplot(data,aes(x=Annual.Income..k.., y=Spending.Score..1.100.)) +
  geom_point(stat='identity', aes(color=as.factor(result$cluster))) +
  scale_color_discrete(name=' ',
                        breaks=c('1','2','3','4','5','6'),
                        labels=c('Cluster 1','Cluster 2','Cluster 3','Cluster 4','Cluster 5','Cluster 6')) +
  ggtitle('Segments of Mall Customers')
```

The visualization of the clusters allows to observe five facts:

1. **Cluster 1 and 5** represent the medium customer in term of spending score and annual income. 

2. **Cluster 2** is regrouping the customers with low income and high spending score.

3. **Cluster 3** is regrouping the customers with low income and low spending score.

4. **Cluster 4** is regrouping the customers with high income and high spending score. 

5. **Cluster 6** is regrouping the customers with high income and low spending score.


## Conclusion 

This paper aimed to perform a customer segmentation in R programming. We used a  Shopping mall customers dataset to implement it. By using the function ***kmeans()*** from the stats package, we found that the Shopping mall customers can be split in 6 clusters. A principal component analysis allowed to have a better understanding of the clusters. We used the ***fviz_cluster()*** from the factoextra package to visualize the results. 
